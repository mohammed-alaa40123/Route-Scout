2025-12-18 19:43:57.961279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/spack/gilbreth-r9/apps/cuda/12.6.0-gcc-11.5.0-a7cv7sp/lib64:/apps/spack/gilbreth-r9/apps/libxml2/2.10.3-gcc-11.5.0-wroyiwb/lib:/apps/spack/gilbreth-r9/apps/libiconv/1.17-gcc-11.5.0-36njf44/lib:/apps/spack/gilbreth-r9/apps/libfabric/1.19.1-gcc-11.5.0-b5idhcg/lib64:/apps/spack/gilbreth-r9/apps/libfabric/1.19.1-gcc-11.5.0-b5idhcg/lib:/apps/spack/gilbreth-r9/apps/openmpi/4.1.6-gcc-11.5.0-w7wc45k/lib
2025-12-18 19:43:57.961818: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-12-18 19:44:01.797543: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-12-18 19:44:01.797631: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gilbreth-fe03.rcac.purdue.edu
2025-12-18 19:44:01.797647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gilbreth-fe03.rcac.purdue.edu
2025-12-18 19:44:01.797718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 565.57.1
2025-12-18 19:44:01.797755: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 565.57.1
2025-12-18 19:44:01.797766: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 565.57.1
2025-12-18 19:44:01.798659: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-12-18 19:44:07.019960: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2025-12-18 19:44:07.634223: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: Assert/AssertGuard/branch_executed/_1017
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).path_update.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).path_update.recurrent_kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).path_update.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).link_update.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).link_update.recurrent_kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).link_update.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).queue_update.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).queue_update.recurrent_kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).queue_update.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).path_embedding.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).path_embedding.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).path_embedding.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).path_embedding.layer_with_weights-1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).queue_embedding.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).queue_embedding.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).queue_embedding.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).queue_embedding.layer_with_weights-1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).link_embedding.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).link_embedding.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).link_embedding.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).link_embedding.layer_with_weights-1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).readout_path.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).readout_path.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).readout_path.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).readout_path.layer_with_weights-1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).readout_path.layer_with_weights-2.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).readout_path.layer_with_weights-2.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).path_update.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).path_update.recurrent_kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).path_update.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).link_update.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).link_update.recurrent_kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).link_update.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).queue_update.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).queue_update.recurrent_kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).queue_update.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).path_embedding.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).path_embedding.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).path_embedding.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).path_embedding.layer_with_weights-1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).queue_embedding.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).queue_embedding.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).queue_embedding.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).queue_embedding.layer_with_weights-1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).link_embedding.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).link_embedding.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).link_embedding.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).link_embedding.layer_with_weights-1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).readout_path.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).readout_path.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).readout_path.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).readout_path.layer_with_weights-1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).readout_path.layer_with_weights-2.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).readout_path.layer_with_weights-2.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.

=== FERMI SCHEDULING MODE B (metric=jitter) ===
Dataset directory : /scratch/gilbreth/mohame43/Routenet/RouteNet-Fermi/data/scheduling/test
Checkpoint dir    : /scratch/gilbreth/mohame43/Routenet/RouteNet-Fermi/scheduling/jitter/ckpt_dir
Sample index      : 1
Routes file       : /scratch/gilbreth/mohame43/Routenet/candidate_routes_scheduling_0_5_test_rediris.txt

[Fermi-Sched] Selected sample_index=1 (graph=graph-rediris-wfq-drr-sp-57.txt, dataset_file=/scratch/gilbreth/mohame43/Routenet/RouteNet-Fermi/data/scheduling/test/gnnet_data_set_0_99.tar.gz)
Baseline sample (Fermi-Sched) uses topology graph: graph-rediris-wfq-drr-sp-57.txt
Loaded baseline sample (Fermi-Sched): n_paths = 342
BEST CHECKPOINT FOUND (Fermi-Sched): 09-29.42028

========================================================================================================================
[Fermi-Sched] Candidate 1: src=0, dst=5, path = 0->5
========================================================================================================================
  idx src dst            route_nodes    traffic    packets   true_jitter_orig   pred_jitter
-------------------------------------------------------------------------------------------
    0   0   1                       0->1    381.534      0.382      0.007269      0.006524
    1   0   2                    0->1->2    330.392      0.332      0.022856      0.020664
    2   0   3                    0->5->3    446.584      0.449      0.002392      0.002455
    3   0   4                    0->1->4    501.475      0.505      0.023655      0.020632
    4   0   5 *                     0->5    325.173      0.328      0.001013      0.001039
    5   0   6                    0->5->6    116.664      0.116      0.004154      0.003179
    6   0   7                    0->5->7     90.727      0.091      0.004066      0.003382
    7   0   8                    0->5->8    288.329      0.286      0.002376      0.002849
    8   0   9                 0->5->8->9    423.096      0.423      0.006067      0.005851
    9   0  10               0->5->11->10    161.804      0.158      0.006033      0.006174
   10   0  11                   0->5->11    506.384      0.506      0.002526      0.002704
   11   0  12               0->5->14->12    490.398      0.492      0.006006      0.006472
   12   0  13                0->5->7->13    377.804      0.379      0.034539      0.039090
   13   0  14                   0->5->14    284.689      0.284      0.002504      0.003149
   14   0  15                   0->5->15    494.119      0.496      0.002333      0.004426
   15   0  16               0->1->17->16    104.064      0.101      0.052574      0.044890
   16   0  17                   0->1->17    386.052      0.392      0.023253      0.022222
   17   0  18                   0->1->18    191.000      0.188      0.022640      0.020990
   18   1   0                       1->0    473.914      0.474      0.007288      0.005615
   19   1   2                       1->2     81.610      0.080      0.007642      0.006826
   20   1   3                    1->2->3    302.510      0.304      0.013020      0.011172
   21   1   4                       1->4    204.633      0.203      0.006749      0.005264
   22   1   5                       1->5    318.665      0.322      0.000403      0.000563
   23   1   6                    1->5->6    261.311      0.260      0.002526      0.002375
   24   1   7                    1->5->7    148.047      0.148      0.002522      0.002183
   25   1   8                    1->5->8    508.568      0.507      0.001437      0.002018
   26   1   9                 1->5->8->9    165.663      0.167      0.004331      0.004271
   27   1  10               1->5->11->10    173.125      0.171      0.004527      0.004125
   28   1  11                   1->5->11     97.666      0.098      0.001423      0.002102
   29   1  12               1->5->14->12    464.709      0.464      0.004282      0.004643
   30   1  13                1->5->7->13    253.981      0.249      0.032449      0.033225
   31   1  14                   1->5->14    166.353      0.167      0.001411      0.001879
   32   1  15                   1->5->15    453.421      0.451      0.001375      0.002624
   33   1  16                  1->17->16    341.784      0.341      0.027263      0.024595
   34   1  17                      1->17    302.406      0.302      0.006172      0.005510
   35   1  18                      1->18    100.942      0.100      0.006238      0.006360
   36   2   0                    2->1->0    174.440      0.175      0.021777      0.014621
   37   2   1                       2->1    477.328      0.479      0.007171      0.004974
   38   2   3                       2->3    433.635      0.434      0.001057      0.001000
   39   2   4                    2->1->4    326.021      0.327      0.023552      0.018366
   40   2   5                    2->3->5    239.465      0.241      0.002440      0.002266
   41   2   6                 2->3->5->6    462.021      0.458      0.006360      0.005844
   42   2   7                 2->3->5->7    464.351      0.461      0.005904      0.005025
   43   2   8                 2->3->5->8    181.165      0.180      0.004387      0.004972
   44   2   9              2->3->5->8->9    408.762      0.405      0.008906      0.008970
   45   2  10            2->3->5->11->10    480.129      0.477      0.008614      0.006648
   46   2  11                2->3->5->11    223.178      0.225      0.004292      0.004366
   47   2  12            2->3->5->14->12    414.752      0.416      0.008784      0.008753
   48   2  13             2->3->5->7->13    379.884      0.381      0.025404      0.024327
   49   2  14                2->3->5->14     69.418      0.070      0.004631      0.005394
   50   2  15                2->3->5->15    200.056      0.204      0.004495      0.005753
   51   2  16               2->1->17->16    306.809      0.304      0.048683      0.034958
   52   2  17                   2->1->17     60.081      0.059      0.022590      0.019917
   53   2  18                   2->1->18    373.387      0.369      0.022598      0.017837
   54   3   0                    3->5->0    420.368      0.422      0.002333      0.003274
   55   3   1                    3->5->1    396.357      0.394      0.001420      0.002316
   56   3   2                       3->2    267.369      0.267      0.000985      0.000867
   57   3   4                    3->5->4    317.019      0.319      0.002423      0.002769
   58   3   5                       3->5    417.266      0.416      0.000423      0.000543
   59   3   6                    3->5->6    225.992      0.227      0.002833      0.002821
   60   3   7                    3->5->7    385.328      0.388      0.002813      0.002388
   61   3   8                    3->5->8    129.044      0.129      0.001553      0.002002
   62   3   9                 3->5->8->9    324.675      0.326      0.004491      0.004511
   63   3  10               3->5->11->10    392.464      0.390      0.004583      0.004267
   64   3  11                   3->5->11     89.531      0.090      0.001511      0.002025
   65   3  12               3->5->14->12    285.458      0.285      0.004384      0.004863
   66   3  13                3->5->7->13    154.662      0.157      0.032321      0.034094
   67   3  14                   3->5->14    405.131      0.408      0.001520      0.001981
   68   3  15                   3->5->15    281.325      0.281      0.001482      0.002604
   69   3  16               3->5->17->16    263.116      0.264      0.021655      0.021729
   70   3  17                   3->5->17    250.023      0.249      0.003245      0.002829
   71   3  18               3->5->17->18    213.387      0.213      0.023711      0.025524
   72   4   0                    4->1->0    142.389      0.144      0.023470      0.018961
   73   4   1                       4->1    249.404      0.251      0.006143      0.003817
   74   4   2                    4->1->2    447.679      0.449      0.024208      0.020000
   75   4   3                    4->5->3    203.501      0.205      0.002494      0.002333
   76   4   5                       4->5    202.496      0.201      0.001062      0.000964
   77   4   6                    4->5->6    486.347      0.485      0.003912      0.003312
   78   4   7                    4->5->7    140.596      0.140      0.003874      0.003174
   79   4   8                    4->5->8    489.491      0.489      0.002388      0.002347
   80   4   9                 4->5->8->9     74.040      0.074      0.005709      0.004804
   81   4  10               4->5->11->10    457.551      0.459      0.005909      0.004137
   82   4  11                   4->5->11    344.529      0.346      0.002443      0.002436
   83   4  12               4->5->14->12    143.420      0.145      0.005969      0.004853
   84   4  13                4->5->7->13    297.351      0.297      0.019082      0.014496
   85   4  14                   4->5->14     81.427      0.082      0.002473      0.002861
   86   4  15                   4->5->15    191.988      0.192      0.002423      0.003103
   87   4  16               4->5->17->16    200.422      0.200      0.022911      0.025132
   88   4  17                   4->5->17    160.509      0.160      0.003889      0.003058
   89   4  18                   4->1->18    475.974      0.477      0.021205      0.013882
   90   5   0                       5->0    198.040      0.197      0.000978      0.001217
   91   5   1                       5->1    403.543      0.402      0.000366      0.000557
   92   5   2                    5->3->2     82.786      0.085      0.002262      0.002167
   93   5   3                       5->3    201.151      0.199      0.000422      0.000355
   94   5   4                       5->4    512.334      0.505      0.001056      0.001216
   95   5   6                       5->6    274.040      0.274      0.001283      0.001228
   96   5   7                       5->7    478.874      0.482      0.001312      0.001159
   97   5   8                       5->8    176.796      0.179      0.000431      0.000565
   98   5   9                    5->8->9    466.277      0.465      0.002503      0.002084
   99   5  10                  5->11->10    475.980      0.475      0.002512      0.001792
  100   5  11                      5->11    449.694      0.447      0.000416      0.000360
  101   5  12                  5->14->12    494.958      0.495      0.002412      0.002619
  102   5  13                   5->7->13    349.421      0.348      0.014921      0.012757
  103   5  14                      5->14    505.120      0.504      0.000394      0.000567
  104   5  15                      5->15    264.546      0.265      0.000352      0.000606
  105   5  16                  5->17->16    150.375      0.152      0.016753      0.014254
  106   5  17                      5->17    506.792      0.505      0.001729      0.001552
  107   5  18                  5->17->18    268.999      0.268      0.015380      0.013024
  108   6   0                    6->5->0     97.100      0.097      0.003645      0.004223
  109   6   1                    6->5->1    401.100      0.401      0.002563      0.002938
  110   6   2                 6->5->3->2    487.954      0.486      0.005876      0.004212
  111   6   3                    6->5->3    229.826      0.230      0.002596      0.002653
  112   6   4                    6->5->4    296.799      0.295      0.003820      0.003508
  113   6   5                       6->5    451.265      0.452      0.001179      0.000458
  114   6   7                    6->5->7    189.649      0.189      0.004160      0.003582
  115   6   8                    6->5->8    393.193      0.397      0.002439      0.002540
  116   6   9                 6->5->8->9    499.693      0.498      0.006092      0.004431
  117   6  10               6->5->11->10    116.650      0.116      0.006294      0.004739
  118   6  11                   6->5->11     70.358      0.071      0.002581      0.002957
  119   6  12               6->5->14->12     94.432      0.094      0.005991      0.004612
  120   6  13                6->5->7->13     97.736      0.098      0.035020      0.042569
  121   6  14                   6->5->14    437.804      0.442      0.002545      0.002983
  122   6  15                   6->5->15    360.399      0.362      0.002515      0.003501
  123   6  16               6->5->17->16    150.719      0.152      0.023869      0.023852
  124   6  17                   6->5->17    235.833      0.236      0.003895      0.003552
  125   6  18               6->5->17->18    300.343      0.298      0.027679      0.030285
  126   7   0                    7->5->0    477.140      0.478      0.003460      0.003892
  127   7   1                    7->5->1    434.319      0.438      0.002446      0.002699
  128   7   2                 7->5->3->2    141.691      0.141      0.005953      0.004782
  129   7   3                    7->5->3    267.465      0.268      0.002485      0.002247
  130   7   4                    7->5->4    423.923      0.425      0.003591      0.003549
  131   7   5                       7->5    399.223      0.399      0.001005      0.000971
  132   7   6                    7->5->6    356.653      0.355      0.003951      0.003399
  133   7   8                       7->8    319.180      0.319      0.006790      0.005327
  134   7   9                    7->8->9    387.794      0.388      0.013083      0.010059
  135   7  10               7->8->11->10    353.286      0.355      0.034519      0.039386
  136   7  11                   7->8->11     63.603      0.064      0.025368      0.027981
  137   7  12               7->8->11->12     72.298      0.072      0.049862      0.049754
  138   7  13                      7->13    458.502      0.459      0.022462      0.020812
  139   7  14                  7->13->14    380.346      0.382      0.015252      0.015965
  140   7  15                   7->5->15    397.987      0.401      0.002328      0.003988
  141   7  16               7->5->17->16    210.778      0.210      0.019407      0.022460
  142   7  17                   7->5->17    154.299      0.156      0.004343      0.003394
  143   7  18               7->5->17->18    177.204      0.175      0.019949      0.016458
  144   8   0                    8->5->0    313.227      0.313      0.002344      0.002767
  145   8   1                    8->5->1    178.367      0.177      0.001373      0.001951
  146   8   2                 8->5->3->2    187.819      0.187      0.004178      0.004350
  147   8   3                    8->5->3    109.016      0.108      0.001424      0.001724
  148   8   4                    8->5->4    453.140      0.450      0.002488      0.002193
  149   8   5                       8->5    271.831      0.268      0.000388      0.000534
  150   8   6                    8->5->6    153.610      0.153      0.002517      0.002637
  151   8   7                       8->7    424.078      0.431      0.007630      0.004326
  152   8   9                       8->9    462.173      0.460      0.001063      0.000939
  153   8  10                  8->11->10    436.334      0.438      0.012548      0.008233
  154   8  11                      8->11    112.244      0.114      0.008853      0.006927
  155   8  12                  8->11->12    438.533      0.437      0.023990      0.023288
  156   8  13                   8->7->13    436.731      0.436      0.038376      0.035567
  157   8  14                   8->5->14    290.060      0.293      0.001400      0.001785
  158   8  15                   8->5->15    187.577      0.188      0.001362      0.002671
  159   8  16               8->5->17->16    391.220      0.394      0.020862      0.019967
  160   8  17                   8->5->17    292.850      0.291      0.003052      0.002734
  161   8  18               8->5->17->18    232.371      0.233      0.024274      0.021993
  162   9   0                 9->8->5->0     60.672      0.061      0.005838      0.006207
  163   9   1                 9->8->5->1     85.745      0.086      0.004164      0.004817
  164   9   2              9->8->5->3->2     83.301      0.085      0.008732      0.007733
  165   9   3                 9->8->5->3    178.699      0.183      0.004290      0.003721
  166   9   4                 9->8->5->4     88.523      0.090      0.006181      0.006381
  167   9   5                    9->8->5    260.334      0.260      0.002479      0.002207
  168   9   6                 9->8->5->6    454.702      0.458      0.006179      0.005827
  169   9   7                    9->8->7     58.389      0.058      0.012186      0.009373
  170   9   8                       9->8    245.384      0.247      0.001162      0.001065
  171   9  10                      9->10    393.652      0.395      0.005213      0.004897
  172   9  11                   9->8->11    177.840      0.176      0.012562      0.009120
  173   9  12               9->8->11->12    327.462      0.327      0.031857      0.024940
  174   9  13                9->8->7->13    232.253      0.231      0.047198      0.048360
  175   9  14                9->8->5->14    255.853      0.253      0.004429      0.004450
  176   9  15                9->8->5->15    292.532      0.291      0.004212      0.004289
  177   9  16            9->8->5->17->16    314.083      0.316      0.027836      0.024980
  178   9  17                9->8->5->17    384.881      0.385      0.006494      0.005584
  179   9  18            9->8->5->17->18    273.232      0.275      0.031557      0.031663
  180  10   0               10->11->5->0    139.197      0.141      0.005849      0.005872
  181  10   1               10->11->5->1    274.446      0.276      0.004185      0.004645
  182  10   2            10->11->5->3->2    320.250      0.319      0.008466      0.007233
  183  10   3               10->11->5->3    381.767      0.383      0.004280      0.004441
  184  10   4               10->11->5->4    149.125      0.151      0.005719      0.005952
  185  10   5                  10->11->5    216.751      0.217      0.002309      0.002163
  186  10   6               10->11->5->6    118.190      0.117      0.005976      0.006111
  187  10   7                10->9->8->7    152.194      0.152      0.031175      0.022115
  188  10   8                   10->9->8    336.681      0.339      0.011519      0.009867
  189  10   9                      10->9    206.460      0.206      0.006283      0.004576
  190  10  11                     10->11    349.565      0.350      0.000948      0.000921
  191  10  12                 10->11->12    125.227      0.125      0.011550      0.008879
  192  10  13            10->9->8->7->13    151.130      0.152      0.062811      0.043109
  193  10  14             10->11->12->14    202.879      0.202      0.017483      0.013744
  194  10  15              10->11->5->15    173.801      0.172      0.004162      0.005553
  195  10  16          10->11->5->17->16    139.791      0.138      0.022827      0.021521
  196  10  17              10->11->5->17    185.052      0.186      0.006605      0.005190
  197  10  18          10->11->5->17->18     91.017      0.092      0.024833      0.021320
  198  11   0                   11->5->0    476.520      0.478      0.002374      0.002881
  199  11   1                   11->5->1    443.738      0.444      0.001388      0.002249
  200  11   2                11->5->3->2    466.181      0.464      0.004224      0.004334
  201  11   3                   11->5->3     72.667      0.074      0.001455      0.001956
  202  11   4                   11->5->4    507.473      0.500      0.002418      0.002367
  203  11   5                      11->5    383.909      0.389      0.000419      0.000485
  204  11   6                   11->5->6    471.862      0.471      0.002705      0.002739
  205  11   7                   11->8->7    431.459      0.433      0.023622      0.016474
  206  11   8                      11->8    416.239      0.414      0.006132      0.005468
  207  11   9                  11->10->9    282.834      0.283      0.011074      0.007962
  208  11  10                     11->10    227.667      0.228      0.001289      0.001074
  209  11  12                     11->12    269.621      0.271      0.007018      0.005464
  210  11  13               11->8->7->13    261.753      0.262      0.064460      0.056459
  211  11  14                 11->12->14    153.016      0.154      0.011570      0.010566
  212  11  15                  11->5->15    166.302      0.168      0.001370      0.002506
  213  11  16              11->5->17->16    414.795      0.416      0.021058      0.020823
  214  11  17                  11->5->17    432.613      0.437      0.003149      0.002959
  215  11  18              11->5->17->18    211.741      0.214      0.018473      0.016681
  216  12   0               12->14->5->0     53.916      0.055      0.005878      0.006551
  217  12   1               12->14->5->1    233.075      0.229      0.004534      0.005650
  218  12   2            12->14->5->3->2    207.118      0.207      0.008370      0.007929
  219  12   3               12->14->5->3    411.172      0.409      0.004599      0.004863
  220  12   4               12->14->5->4    332.743      0.333      0.006031      0.006450
  221  12   5                  12->14->5    319.000      0.319      0.002470      0.002678
  222  12   6               12->14->5->6    433.700      0.433      0.006137      0.006147
  223  12   7               12->14->5->7    479.417      0.480      0.006107      0.005434
  224  12   8                  12->11->8    253.542      0.256      0.022936      0.017112
  225  12   9              12->11->10->9    150.581      0.151      0.030980      0.029901
  226  12  10                 12->11->10    400.380      0.399      0.011915      0.009280
  227  12  11                     12->11    223.755      0.222      0.006153      0.005035
  228  12  13                 12->14->13    253.998      0.255      0.003532      0.037482
  229  12  14                     12->14    155.293      0.156      0.001254      0.001217
  230  12  15                 12->14->15    399.946      0.402      0.012864      0.008717
  231  12  16             12->14->15->16    485.190      0.485      0.030426      0.027782
  232  12  17              12->14->5->17    299.521      0.299      0.006520      0.005645
  233  12  18          12->14->5->17->18    348.495      0.345      0.025768      0.023694
  234  13   0               13->14->5->0    401.449      0.401      0.005910      0.006100
  235  13   1               13->14->5->1    475.493      0.475      0.004352      0.005774
  236  13   2            13->14->5->3->2    359.597      0.363      0.008626      0.007604
  237  13   3               13->14->5->3    246.950      0.247      0.004287      0.005011
  238  13   4               13->14->5->4     69.255      0.072      0.006052      0.006627
  239  13   5                  13->14->5    269.339      0.268      0.002471      0.002760
  240  13   6               13->14->5->6    268.484      0.272      0.006311      0.006245
  241  13   7                      13->7    449.511      0.451      0.006597      0.005402
  242  13   8                   13->7->8    390.744      0.391      0.022428      0.017445
  243  13   9                13->7->8->9    186.916      0.187      0.029934      0.024229
  244  13  10           13->7->8->11->10     84.928      0.085      0.060859      0.059195
  245  13  11               13->7->8->11    325.232      0.324      0.049205      0.047450
  246  13  12                 13->14->12    132.951      0.136      0.003633      0.003010
  247  13  14                     13->14    483.873      0.483      0.001128      0.001138
  248  13  15                 13->14->15    497.933      0.498      0.012591      0.011226
  249  13  16             13->14->15->16    104.602      0.105      0.030414      0.027876
  250  13  17              13->14->5->17    116.698      0.116      0.006292      0.006224
  251  13  18          13->14->5->17->18    298.589      0.298      0.032861      0.031491
  252  14   0                   14->5->0     62.339      0.062      0.002481      0.003358
  253  14   1                   14->5->1    472.047      0.472      0.001415      0.002218
  254  14   2                14->5->3->2    388.022      0.385      0.004232      0.004580
  255  14   3                   14->5->3    292.734      0.295      0.001555      0.001773
  256  14   4                   14->5->4    404.014      0.407      0.002590      0.002290
  257  14   5                      14->5    326.294      0.328      0.000454      0.000560
  258  14   6                   14->5->6    417.708      0.419      0.002597      0.002775
  259  14   7                   14->5->7     96.579      0.098      0.002580      0.002339
  260  14   8                   14->5->8    152.045      0.152      0.001492      0.001948
  261  14   9                14->5->8->9     79.529      0.078      0.004476      0.004994
  262  14  10             14->12->11->10    161.421      0.164      0.018542      0.016785
  263  14  11                 14->12->11    238.930      0.237      0.010976      0.009253
  264  14  12                     14->12    478.308      0.477      0.001051      0.001022
  265  14  13                     14->13     64.301      0.064      0.000847      0.082571
  266  14  15                     14->15    204.740      0.204      0.007636      0.005478
  267  14  16                 14->15->16    406.018      0.409      0.021992      0.016107
  268  14  17                  14->5->17    131.135      0.131      0.003043      0.003009
  269  14  18              14->5->17->18    174.342      0.175      0.024866      0.022371
  270  15   0                   15->5->0    148.506      0.146      0.002362      0.002794
  271  15   1                   15->5->1    460.326      0.459      0.001366      0.002080
  272  15   2                15->5->3->2    120.036      0.118      0.004233      0.004129
  273  15   3                   15->5->3    426.862      0.426      0.001418      0.001754
  274  15   4                   15->5->4    481.179      0.481      0.002382      0.002316
  275  15   5                      15->5    121.055      0.119      0.000378      0.000354
  276  15   6                   15->5->6    404.962      0.407      0.002495      0.002389
  277  15   7                   15->5->7    140.019      0.141      0.002418      0.002161
  278  15   8                   15->5->8    296.920      0.292      0.001445      0.001847
  279  15   9                15->5->8->9    145.047      0.143      0.004284      0.003908
  280  15  10              15->5->11->10    239.558      0.241      0.004503      0.003759
  281  15  11                  15->5->11    462.437      0.461      0.001396      0.001388
  282  15  12                 15->14->12    155.434      0.157      0.013893      0.011360
  283  15  13                 15->14->13    485.964      0.487      0.013562      0.053075
  284  15  14                     15->14    504.577      0.506      0.008679      0.007180
  285  15  16                     15->16    217.480      0.217      0.005881      0.003248
  286  15  17                     15->17    311.929      0.313      0.005718      0.003431
  287  15  18                 15->17->18    493.151      0.494      0.025616      0.020999
  288  16   0               16->17->1->0    268.990      0.270      0.048792      0.040890
  289  16   1                  16->17->1    382.336      0.383      0.022723      0.018278
  290  16   2               16->17->1->2    202.249      0.200      0.050063      0.042470
  291  16   3               16->15->5->3    396.498      0.399      0.013203      0.009091
  292  16   4               16->17->1->4    112.599      0.114      0.047679      0.037694
  293  16   5                  16->15->5    200.971      0.198      0.013257      0.012473
  294  16   6               16->15->5->6     70.741      0.071      0.015822      0.018418
  295  16   7               16->15->5->7    181.213      0.179      0.019633      0.019959
  296  16   8               16->15->5->8    225.252      0.224      0.017621      0.014296
  297  16   9            16->15->5->8->9    207.510      0.210      0.023641      0.023443
  298  16  10          16->15->5->11->10    282.043      0.285      0.023468      0.027288
  299  16  11              16->15->5->11    243.954      0.245      0.017107      0.015169
  300  16  12             16->15->14->12    189.995      0.188      0.032488      0.025756
  301  16  13             16->15->14->13    214.296      0.214      0.032347      0.058567
  302  16  14                 16->15->14    315.141      0.313      0.029981      0.028045
  303  16  15                     16->15    457.697      0.456      0.011003      0.010172
  304  16  17                     16->17    174.674      0.173      0.006813      0.005582
  305  16  18                 16->17->18    370.440      0.367      0.026234      0.021639
  306  17   0                   17->1->0    283.268      0.286      0.023544      0.018161
  307  17   1                      17->1    354.840      0.353      0.006764      0.005486
  308  17   2                   17->1->2    206.268      0.209      0.025289      0.022113
  309  17   3                   17->5->3    113.528      0.113      0.002335      0.004326
  310  17   4                   17->1->4    258.876      0.257      0.022702      0.017093
  311  17   5                      17->5    122.722      0.124      0.000927      0.001570
  312  17   6                   17->5->6    398.651      0.397      0.003754      0.004842
  313  17   7                   17->5->7    192.962      0.195      0.003518      0.004411
  314  17   8                   17->5->8    468.166      0.465      0.002317      0.004290
  315  17   9                17->5->8->9    324.149      0.324      0.005705      0.006503
  316  17  10              17->5->11->10    299.667      0.295      0.005745      0.005395
  317  17  11                  17->5->11    194.831      0.193      0.002308      0.003828
  318  17  12             17->15->14->12    153.083      0.152      0.032241      0.028794
  319  17  13             17->15->14->13    198.485      0.202      0.030456      0.059448
  320  17  14                 17->15->14    311.507      0.311      0.024554      0.022335
  321  17  15                     17->15    438.330      0.439      0.006788      0.005772
  322  17  16                     17->16    265.877      0.264      0.011651      0.008716
  323  17  18                     17->18    306.403      0.308      0.009599      0.007963
  324  18   0                   18->1->0    437.534      0.437      0.030128      0.024258
  325  18   1                      18->1    202.533      0.199      0.028012      0.027325
  326  18   2                   18->1->2    154.710      0.154      0.030099      0.025377
  327  18   3                18->1->2->3    319.135      0.315      0.033647      0.028562
  328  18   4                   18->1->4    256.751      0.256      0.046030      0.039708
  329  18   5                   18->1->5    172.154      0.171      0.030400      0.025647
  330  18   6                18->1->5->6    245.880      0.246      0.022010      0.022601
  331  18   7                18->1->5->7     64.222      0.064      0.042299      0.036855
  332  18   8                18->1->5->8    319.580      0.320      0.035768      0.028132
  333  18   9             18->1->5->8->9    413.562      0.412      0.025876      0.023070
  334  18  10           18->1->5->11->10    260.653      0.259      0.021131      0.021388
  335  18  11               18->1->5->11    395.349      0.400      0.014736      0.011467
  336  18  12           18->1->5->14->12    172.433      0.174      0.039212      0.041188
  337  18  13            18->1->5->7->13    458.465      0.453      0.040017      0.032506
  338  18  14               18->1->5->14    486.944      0.484      0.036222      0.028116
  339  18  15                 18->17->15    321.956      0.320      0.021214      0.014724
  340  18  16                 18->17->16    192.731      0.191      0.026258      0.021748
  341  18  17                     18->17    155.059      0.159      0.005578      0.004019
